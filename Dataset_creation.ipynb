{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec49ea1-fb9e-4ee5-8c4e-835b41e5a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./stations_day_dataset.csv')\n",
    "df.head()\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8073b6f-cddc-4ae7-9562-1d90c3b9cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def impute_strategy(df):\n",
    "    result = []\n",
    "    for station_id,group in df.groupby('StationId'):\n",
    "        numeric_columns = group.select_dtypes(include='number').columns\n",
    "        row_count = len(group)\n",
    "        for col in numeric_columns:\n",
    "            null_count = group[col].isnull().sum()\n",
    "            null_pct = null_count / row_count\n",
    "            if null_count == row_count:\n",
    "                skew = np.nan\n",
    "            else:\n",
    "                skew = group[col].dropna().skew()\n",
    "            result.append({\n",
    "                'StationId': station_id,\n",
    "                'Column': col,\n",
    "                'Nulls': null_count,\n",
    "                'TotalRows': row_count,\n",
    "                'NullPct': null_pct,\n",
    "                'Skew': skew\n",
    "            })\n",
    "    return pd.DataFrame(result)\n",
    "summary_df = impute_strategy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90beb89d-f34b-4c78-9eb7-60d432cf24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def impute_values_station_wise(df):\n",
    "    for station_id,group in df.groupby('StationId'):\n",
    "        numeric_columns = group.select_dtypes(include='number').columns\n",
    "        row_count = len(group)\n",
    "        for col in numeric_columns:\n",
    "            null_count_col = group[col].isnull().sum()\n",
    "            null_pct =  null_count_col/row_count\n",
    "            \n",
    "            if null_pct <= 0.5:\n",
    "                skew_value = group[col].dropna().skew()\n",
    "                if skew_value > 0.5 or skew_value < -0.5:\n",
    "                    df.loc[group.index,col] = group[col].fillna(group[col].median())\n",
    "                else:\n",
    "                    df.loc[group.index,col] = group[col].fillna(group[col].mean())\n",
    "impute_values_station_wise(df)\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d394ee1-51e3-482f-ad78-1ca084867426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def impute_values_city_wise(df):\n",
    "    for City,group in df.groupby('City'):\n",
    "        numeric_columns = group.select_dtypes(include='number').columns\n",
    "        row_count = len(group)\n",
    "        for col in numeric_columns:\n",
    "            null_count_col = group[col].isnull().sum()\n",
    "            null_pct =  null_count_col/row_count\n",
    "            \n",
    "            if null_pct <= 0.5:\n",
    "                skew_value = group[col].dropna().skew()\n",
    "                if skew_value > 0.5 or skew_value < -0.5:\n",
    "                    df.loc[group.index,col] = group[col].fillna(group[col].median())\n",
    "                else:\n",
    "                    df.loc[group.index,col] = group[col].fillna(group[col].mean())\n",
    "impute_values_city_wise(df)\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f03c8-0026-4cfb-b19f-5b9d9a01cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def impute_values_state_wise(df):\n",
    "    for state,group in df.groupby('State'):\n",
    "        numeric_columns = group.select_dtypes(include='number').columns\n",
    "        row_count = len(group)\n",
    "        for col in numeric_columns:\n",
    "            null_count_col = group[col].isnull().sum()\n",
    "            null_pct =  null_count_col/row_count\n",
    "            \n",
    "            if null_pct <= 0.5:\n",
    "                skew_value = group[col].dropna().skew()\n",
    "                if skew_value > 0.5 or skew_value < -0.5:\n",
    "                    df.loc[group.index,col] = group[col].fillna(group[col].median())\n",
    "                else:\n",
    "                    df.loc[group.index,col] = group[col].fillna(group[col].mean())\n",
    "impute_values_state_wise(df)\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1ddfc-4c76-45ff-b613-ae036d1d3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Impute remanining values with rest of median or mean based on skew value\n",
    "\n",
    "numeric_columns = df.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numeric_columns:\n",
    "    skew = df[col].dropna().skew()\n",
    "    if skew > 0.5 or skew < -0.5:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "df.isnull().sum().sort_values(ascending=False)\n",
    "df.to_csv('./stations_cleaned.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c9566e-ee91-4881-a12c-210091ca097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = pd.to_datetime(df['Date']).dt.month\n",
    "monthly_average_pm = df.groupby(['Month'])['PM2.5'].mean().reset_index()\n",
    "monthly_average_pm.columns = ['Month', 'Avg_PM2.5']\n",
    "monthly_average_pm.sort_values(by='Avg_PM2.5', ascending=False)\n",
    "def get_season(month):\n",
    "    if month in [10,11,12,1,2]:\n",
    "        return \"Winter\"\n",
    "    if month in [3,4,5]:\n",
    "        return \"Summer\"\n",
    "    if month in [6,7,8,9]:\n",
    "        return \"Rainy\"\n",
    "df['Season'] = df['Month'].apply(get_season)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa23ac7-e6f2-40de-af50-7da9100a99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.histplot(data=df,x='PM2.5',bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a277fd-cd68-44e1-92ff-2ec90e293289",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "monthly_avg_pm = df.groupby('Month')['PM2.5'].mean().reset_index()\n",
    "print(monthly_avg_pm)\n",
    "sns.barplot(data=monthly_avg_pm,x='Month',y='PM2.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9895823-76c2-4ed3-8514-477d9bd18b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "season_avg_pm = df.groupby('Season')['PM2.5'].mean().reset_index()\n",
    "print(season_avg_pm)\n",
    "sns.barplot(data=season_avg_pm,x='Season',y='PM2.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63c28c-4cfd-4a6e-842a-a7e4e737805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day'] = pd.to_datetime(df['Date']).dt.dayofweek\n",
    "daily_avg_pm = df.groupby('Day')['PM2.5'].mean().reset_index()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data=daily_avg_pm,x='Day',y='PM2.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69309424-841d-4c10-8b75-37c5439c8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.scatterplot(data=df,x='temperature_2m',y='PM2.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e253ec5-4674-404c-bc18-5b5f6664e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "df['PM2.5_zscore'] = zscore(df['PM2.5'])\n",
    "df['PM2.5_outlier_flag'] = df['PM2.5_zscore'].abs() > 3\n",
    "(df['PM2.5_outlier_flag'] == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aaf11e-89ce-4b98-99d9-11daf931d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "plt.figure(figsize=(13,9))\n",
    "correlation_data = df[['PM2.5', 'PM10', 'SO2', 'NO2',\n",
    "                         'CO', 'O3', 'temperature_2m', 'relative_humidity_2m',\n",
    "                         'windspeed_10m', 'NO', 'NOx','NH3','Benzene','Toluene']]\n",
    "sns.heatmap(correlation_data.corr(),cmap=plt.cm.Reds,annot=True)\n",
    "plt.title('Heatmap displaying the correlation matrix of the variables',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01d5fd-3cf4-46b2-8248-7065b2473715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PM2.5_outlier_flag'] = df['PM2.5_outlier_flag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1aca72-ed3d-4208-aaec-11665e0fb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['AQI','AQI_Bucket','Unnamed: 0','FullAddress','StationName','FullAddress','StationId','location','longitude','latitude','Month','Date','State','PM2.5_flagged','Day','PM2.5_zscore'],inplace=True,errors='ignore')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c008e3c-d3a4-4b03-8384-0a2946f3e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df,columns=['City','Season'],drop_first=True)\n",
    "df_encoded['PM2.5_outlier_flag'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93298ea-2161-4826-b5e2-045c3e936d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded.to_csv('./stations_encoded.csv',index=False)\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada04782-70af-4c9b-81bb-23c8ee04fb0f",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "327f2c47-5c22-457d-a6ec-b2a777bf84bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3',\n",
       "       'Benzene', 'Toluene', 'road_distance', 'river_distance',\n",
       "       'industry_distance', 'temperature_2m', 'relative_humidity_2m',\n",
       "       'windspeed_10m', 'PM2.5_outlier_flag', 'City_Aizawl', 'City_Amaravati',\n",
       "       'City_Amritsar', 'City_Bengaluru', 'City_Bhopal', 'City_Brajrajnagar',\n",
       "       'City_Chandigarh', 'City_Chennai', 'City_Coimbatore', 'City_Delhi',\n",
       "       'City_Ernakulam', 'City_Gurugram', 'City_Guwahati', 'City_Hyderabad',\n",
       "       'City_Jaipur', 'City_Jorapokhar', 'City_Kochi', 'City_Kolkata',\n",
       "       'City_Lucknow', 'City_Mumbai', 'City_Patna', 'City_Shillong',\n",
       "       'City_Talcher', 'City_Thiruvananthapuram', 'City_Visakhapatnam',\n",
       "       'Season_Summer', 'Season_Winter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_encoded\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd7a37-d0e8-4f04-9c1d-2e1621e20e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(df.columns)  \n",
    "numeric_df = df.select_dtypes(include='number')\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix[['PM2.5']].sort_values(by='PM2.5', ascending=False), \n",
    "            annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation of Features with PM2.5')\n",
    "plt.show()\n",
    "# df.drop(columns=['road_distance','river_distance','industry_distance'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "609c60d0-18ba-47cc-b15d-bef56bc450aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['PM2.5'])\n",
    "y = df['PM2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9084279-84b1-4ff1-9d8d-e13708cc23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = X.select_dtypes(include='number').columns\n",
    "categorical_columns = X.drop(columns=numeric_columns)\n",
    "scaled_array = scaler.fit_transform(X[numeric_columns])\n",
    "scaled_numeric_X = pd.DataFrame(scaled_array, columns=numeric_columns, index=X.index)\n",
    "df = pd.concat([categorical_columns,scaled_numeric_X],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813579f-f317-44b7-ae29-4545cb34978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(\"PM2.5 mean:\", y.mean())\n",
    "print(\"PM2.5 std deviation:\", y.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f97db-22d2-486f-8571-b7516511067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train,y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_dt))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred_dt))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cf3f9c65-9db5-434f-a1d8-30423892ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "R² Score: 0.8950308241769108\n",
      "RMSE: 595.9108734286533\n",
      "MAE: 13.910725407183236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42,max_depth=30,n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78868afe-99d5-416d-9d1d-d32c75b9faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 100],\n",
    "    'max_depth': [30, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'max_features': ['log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred_rf_best = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest:\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_rf_best))\n",
    "print(\"RMSE:\", mean_squared_error(y_test, y_pred_rf_best))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ca539-49cf-4d35-814f-97c3ca66e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,root_mean_squared_error\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 200),\n",
    "    'max_depth': randint(10, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=12,          \n",
    "    cv=2,               \n",
    "    scoring='r2',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest (RandomizedSearchCV):\")\n",
    "print(\"Best Params:\", random_search.best_params_)\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"RMSE:\", root_mean_squared_error(y_test, y_pred_rf, squared=False))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbd280fd-a936-46ef-8aaf-fa09c44f94fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "R² Score: 0.8950308241769108\n",
      "RMSE: 24.411285779914447\n",
      "MAE: 13.910725407183238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,root_mean_squared_error\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42,max_depth=30,n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_rf))\n",
    "print(\"RMSE:\", root_mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "815126ed-8003-40aa-9ecb-f431d5f30854",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'latitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Add actual PM2.5 layer\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_map\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     15\u001b[0m     folium\u001b[38;5;241m.\u001b[39mCircleMarker(\n\u001b[1;32m---> 16\u001b[0m         location\u001b[38;5;241m=\u001b[39m[row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     17\u001b[0m         radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     18\u001b[0m         popup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mActual: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPM2.5_actual\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPM2.5_predicted\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m         fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m         fill_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m         fill_opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     23\u001b[0m     )\u001b[38;5;241m.\u001b[39madd_to(delhi_map)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Add predicted PM2.5 layer (with slight offset to visualize both if needed)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_map\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'latitude'"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import pandas as pd\n",
    "\n",
    "# Combine actual and predicted into a DataFrame with coordinates\n",
    "df_map = X_test.copy()\n",
    "df_map['PM2.5_actual'] = y_test.values\n",
    "df_map['PM2.5_predicted'] = y_pred_rf\n",
    "\n",
    "# Create base map centered on Delhi\n",
    "delhi_map = folium.Map(location=[28.6139, 77.2090], zoom_start=10)\n",
    "\n",
    "# Add actual PM2.5 layer\n",
    "for _, row in df_map.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        radius=5,\n",
    "        popup=f\"Actual: {row['PM2.5_actual']:.2f}\\nPredicted: {row['PM2.5_predicted']:.2f}\",\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='blue',\n",
    "        fill_opacity=0.5\n",
    "    ).add_to(delhi_map)\n",
    "\n",
    "# Add predicted PM2.5 layer (with slight offset to visualize both if needed)\n",
    "for _, row in df_map.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['latitude'] + 0.002, row['longitude'] + 0.002],  # Slight offset\n",
    "        radius=5,\n",
    "        popup=f\"Predicted: {row['PM2.5_predicted']:.2f}\",\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.5\n",
    "    ).add_to(delhi_map)\n",
    "\n",
    "# Show map\n",
    "delhi_map.save(\"delhi_pm25_comparison_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74949c47-6efe-4049-9b9b-8ee285637057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_rf, alpha=0.5)\n",
    "\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "\n",
    "plt.xlabel(\"Actual PM2.5\")\n",
    "plt.ylabel(\"Predicted PM2.5\")\n",
    "plt.title(\"Predicted vs Actual PM2.5 - Random Forest\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
